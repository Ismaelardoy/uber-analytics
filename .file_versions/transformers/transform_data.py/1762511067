if 'transformer' not in globals():
    from mage_ai.data_preparation.decorators import transformer
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test

import sys
sys.path.append('src')
from etl.transform import transform_data
from etl.spark_session import get_spark_session

@transformer
def transform(zonedata, tripdata, *args, **kwargs):
    """
    Transformer block: carga los datos desde los paths Parquet,
    aplica la transformaciÃ³n con PySpark y guarda el resultado.
    """
    # 1ï¸âƒ£ Crear sesiÃ³n Spark
    spark = get_spark_session("UberDataTransform")

    # 2ï¸âƒ£ Extraer rutas de los Parquet
    path_zones = zonedata.get('data_path')
    path_tripdata = tripdata.get('data_path')

    print(f"ğŸ“‚ Leyendo zonas desde: {path_zones}")
    print(f"ğŸ“‚ Leyendo viajes desde: {path_tripdata}")

    # 3ï¸âƒ£ Leer los Parquet
    df_zones = spark.read.parquet(path_zones)
    df_tripdata = spark.read.parquet(path_tripdata)

    # 4ï¸âƒ£ Transformar los datos usando tu funciÃ³n ETL
    df_transformed = transform_data(df_tripdata, df_zones)

    # 5ï¸âƒ£ Guardar resultado
    output_path = '/tmp/transformed_data.parquet'
    df_transformed.write.mode('overwrite').parquet(output_path)

    print(f"âœ… Transformed data saved to: {output_path}")

    return {'data_path': output_path}


@test
def test_output(output, *args) -> None:
    """
    Test del bloque transformer.
    """
    assert output is not None, 'The output is undefined'
    assert 'data_path' in output, 'Output should contain a data_path key'